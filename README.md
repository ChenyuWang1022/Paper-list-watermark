# Paper-list-watermark

This is the paper list of LLM watermark methods.

Watermarking can be divided into two categories: one is to add watermarks to already generated text, and the other is to add watermark during the text generation process.

## watermarking for existing text

[UniSpaCh: A text-based data hiding method using Unicode space characters.](https://doi.org/10.1016/j.jss.2011.12.023)  </br></br>
[Content-preserving Text Watermarking through Unicode Homoglyph Substitution](https://dl.acm.org/doi/10.1145/2938503.2938510) </br></br>
[Embarrassingly Simple Text Watermarks](https://arxiv.org/pdf/2310.08920.pdf) </br></br>
</br>

[Deeptextmark: Deep learning based text watermarking for detection of large language model generated text.](https://arxiv.org/pdf/2305.05773.pdf) </br></br>
[Watermarking Text Generated by Black-Box Language Models.](https://arxiv.org/pdf/2305.08883.pdf) </br></br>
[Robust multi-bit natural language watermarking through invariant features.](https://aclanthology.org/2023.acl-long.117/) </br></br>
[REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.](https://arxiv.org/pdf/2310.12362.pdf) </br></br>

## watermarking for LLMs
### watermark during training

### watermark during logits generation
[A Watermark for Large Language Models](https://proceedings.mlr.press/v202/kirchenbauer23a.html)  </br></br>
[On the Reliability of Watermarks for Large Language Models](https://arxiv.org/pdf/2306.04634.pdf)  </br></br>
[Who Wrote this Code? Watermarking for Code Generation](https://arxiv.org/pdf/2305.15060.pdf) </br></br>
[Unbiased Watermark for Large Language Models.](https://arxiv.org/pdf/2310.10669.pdf) </br></br>
[DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models.](https://arxiv.org/pdf/2310.07710.pdf) </br></br>
[Advancing Beyond Identification: Multi-bit Watermark for Large Language Models](https://arxiv.org/pdf/2308.00221.pdf) </br></br>
[Towards Codable Watermarking for Injecting Multi-bit Information to LLM](https://arxiv.org/pdf/2307.15992.pdf) </br></br>
[Provable Robust Watermarking for AI-Generated Text](https://arxiv.org/pdf/2306.17439.pdf) </br></br>
[A Semantic Invariant Robust Watermark for Large Language Models](https://arxiv.org/pdf/2310.06356.pdf) </br></br>
[An Unforgeable Publicly Verifiable Watermark for Large Language Models](https://arxiv.org/pdf/2307.16230.pdf) </br></br>
[Publicly Detectable Watermarking for Language Models](https://eprint.iacr.org/2023/1661) </br></br>
[A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://arxiv.org/pdf/2311.08721.pdf) </br></br>


### watermark during sampling token



